# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1onRmFb2AsG1BGrhrjaJ7ACNY9kQaJdkN
"""

import cv2
import matplotlib.pyplot as plt
from google.colab import files

# Upload video file
uploaded = files.upload()  # This will prompt you to upload a file

# Get the uploaded file name (assuming it's the first file in the upload)
video_file = list(uploaded.keys())[0]  # Get the uploaded file's name

# Load video or camera feed
cap = cv2.VideoCapture(video_file)  # Use the uploaded video file

# Predefined parking positions (list of top-left x, y coordinates)
parking_spots = [(60, 100), (160, 100), (260, 100), (360, 100)]
spot_width, spot_height = 80, 160

# Function to check if a parking spot is empty
def check_parking_spot(img, x, y, w, h):
    roi = img[y:y+h, x:x+w]
    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
    blur = cv2.GaussianBlur(gray, (5, 5), 1)
    thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                   cv2.THRESH_BINARY_INV, 25, 16)
    non_zero = cv2.countNonZero(thresh)
    return non_zero < 900  # Threshold for empty spot

while True:
    ret, frame = cap.read()
    if not ret:
        break

    # Loop through predefined parking spots and check for availability
    for pos in parking_spots:
        x, y = pos
        empty = check_parking_spot(frame, x, y, spot_width, spot_height)
        color = (0, 255, 0) if empty else (0, 0, 255)  # Green if empty, Red if occupied
        cv2.rectangle(frame, (x, y), (x+spot_width, y+spot_height), color, 2)
        status = "Empty" if empty else "Occupied"
        cv2.putText(frame, status, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

    # Convert the frame to RGB (for correct display with matplotlib)
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # Display using matplotlib
    plt.imshow(frame_rgb)
    plt.axis('off')  # Hide axes
    plt.show()

    # Optional: Exit after 1 iteration for testing, remove for continuous run
    break

cap.release()
import torch
import numpy as np
from ultralytics import YOLO
from utilis import YOLO_Detection, drawPolygons, label_detection
import pickle


# Check if CUDA is available
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
# Load YOLO model and move it to the appropriate device
model = YOLO(r"C:\Users\x\3D Objects\car_parking_space_detector_YOLOv8-master\car_parking_space_detector_YOLOv8-master\yolov8n.pt")
model.to(device)

# Load the positions from the pickle file
with open(r'C:\Users\x\3D Objects\car_parking_space_detector_YOLOv8-master\car_parking_space_detector_YOLOv8-master\Space_ROIs', 'rb') as f:
    posList = pickle.load(f)

# Capture from camera or video
cap = cv2.VideoCapture(r"C:\Users\x\3D Objects\car_parking_space_detector_YOLOv8-master\car_parking_space_detector_YOLOv8-master\input_video\parking_space.mp4")  # Change to the appropriate source if not using a webcam
# get vcap property
width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)  # float `width`
height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float `height`

                                        #### Main Loop ####
try:
    while True:
        ret, frame = cap.read()
        if not ret:
            break

        # Perform YOLO detection
        boxes, classes, names = YOLO_Detection(model, frame)

        # Collect points to determine if any detection is inside polygons
        detection_points = []
        for box in boxes:
            x1, y1, x2, y2 = box
            center_x = ((x1 + x2) / 2)
            center_y = ((y1 + y2) / 2)
            detection_points.append((int(center_x), int(center_y)))

        # Draw polygons with updated color based on detection status and make them transparent
        frame, occupied_count = drawPolygons(frame, posList, detection_points=detection_points)
        # Calculate available polygons
        available_count = len(posList) - occupied_count
        # Display the counts on the frame
        font = cv2.FONT_HERSHEY_SIMPLEX
        cv2.rectangle(frame, (int((width/2) - 200), 5), (int((width/2) - 40), 40), (250, 250, 250), -1)  # Rectangle dimensions and color
        # Put the current time on top of the black rectangle
        cv2.putText(frame, f"Fill Slots: {occupied_count}", (int((width/2) - 190), 30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.95,
                    (50, 50, 50), 1, cv2.LINE_AA)
        cv2.rectangle(frame, (int(width/2), 5), (int((width/2) + 175), 40), (250, 250, 250), -1)  # Rectangle dimensions and color
        # Put the current time on top of the black rectangle
        cv2.putText(frame, f"Free Slots: {available_count}", (int((width/2) + 10), 30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.95,
                    (50, 50, 50), 1, cv2.LINE_AA)

        # Iterate through the results
        for box, cls in zip(boxes, classes):
            x1, y1, x2, y2 = box
            detected_class = cls
            name = names[int(cls)]

            # Calculate the center point of the bounding box
            center_x = ((x1 + x2) / 2)
            center_y = ((y1 + y2) / 2)
            center_point = (int(center_x), int(center_y))

            # Define the color of the circle (BGR format)
            circle_color = (0, 120, 0)  # Green color in BGR
            cv2.circle(frame, center_point, 1, (255, 255, 255), thickness=2)

            # Determine the color of the bounding box based on detection location
            detection_in_polygon = False
            for pos in posList:
                matching_result = cv2.pointPolygonTest(np.array(pos, dtype=np.int32), center_point, False)
                if matching_result >= 0:
                    detection_in_polygon = True
                    break

            if detection_in_polygon:
                label_detection(frame=frame, text=str(name), tbox_color=(50, 50, 50), left=x1, top=y1, bottom=x2, right=y2)
            else:
                label_detection(frame=frame, text=str(name), tbox_color=(100, 25, 50), left=x1, top=y1, bottom=x2, right=y2)
        cv2.imshow("Frame", frame)
        if cv2.waitKey(1) & 0xFF == ord("q"):
            break

    cap.release()
    cv2.destroyAllWindows()

except:
    raise NotImplementedError